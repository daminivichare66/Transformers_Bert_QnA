{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ORshxh8Onc8"
   },
   "source": [
    "### Install Necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcEzTwphv_bM",
    "outputId": "9162a53b-748d-486b-b904-1ca3ccf3e474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.2.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.25.2)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.34.88)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (4.66.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2023.12.25)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.1->pytorch_pretrained_bert) (12.4.127)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.88 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_pretrained_bert) (1.34.88)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.88->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.88->boto3->pytorch_pretrained_bert) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Urr1u83NO3J2"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Eu-vG1ZFibpr"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, BertForQuestionAnswering\n",
    "from transformers import AdamW\n",
    "import string, re\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wF4LtA3ePHnt"
   },
   "source": [
    "# 1. Load the SQUAD 2.0\n",
    "\n",
    "**Note: I have downloaded the train and dev files from https://rajpurkar.github.io/SQuAD-explorer/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "tB1aiT1ppGhC"
   },
   "outputs": [],
   "source": [
    "def load_data(path, size):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "    texts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    count = 0\n",
    "    for data in squad_dict['data']:\n",
    "        for para in data['paragraphs']:\n",
    "            text = para['context']\n",
    "            for qas in para['qas']:\n",
    "                question = qas['question']\n",
    "                for answer in qas['answers']:\n",
    "                    texts.append(text)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "                    count += 1\n",
    "                    if count >= size:\n",
    "                        return texts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "miyf-Ah2hWzn"
   },
   "outputs": [],
   "source": [
    "train_texts, train_questions, train_answers = load_data(\"train-v2.0.json\", size=800)\n",
    "val_texts, val_questions, val_answers = load_data(\"dev-v2.0.json\", size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKVHwA0vuvut",
    "outputId": "27018bc9-44ce-46d9-fe52-de2731114262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "800\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts))\n",
    "print(len(train_questions))\n",
    "print(len(train_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZ0eKxRYhWt1",
    "outputId": "bc0e1275-d2e4-4d65-a8fb-6c3dfeee8076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(val_texts))\n",
    "print(len(val_questions))\n",
    "print(len(val_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXBVwswAQEG5"
   },
   "source": [
    "# 2. Display a few raw QnA data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jv7KzGp_cK9C",
    "outputId": "b7a77133-ae11-442c-dde3-c34ea2595e3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA\n",
      "Text:  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "Question:  When did Beyonce start becoming popular?\n",
      "Answer:  {'text': 'in the late 1990s', 'answer_start': 269}\n",
      "\n",
      "\n",
      "Text:  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "Question:  What areas did Beyonce compete in when she was growing up?\n",
      "Answer:  {'text': 'singing and dancing', 'answer_start': 207}\n",
      "\n",
      "\n",
      "Text:  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "Question:  When did Beyonce leave Destiny's Child and become a solo singer?\n",
      "Answer:  {'text': '2003', 'answer_start': 526}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DATA\")\n",
    "for idx in range(0, 3):\n",
    "    print(\"Text: \", train_texts[idx])\n",
    "    print(\"Question: \", train_questions[idx])\n",
    "    print(\"Answer: \", train_answers[idx])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Kb0m-xGcz63",
    "outputId": "33f84986-294b-460d-8997-dd9681e62ff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL DATA\n",
      "Text:  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "Question:  In what country is Normandy located?\n",
      "Answer:  {'text': 'France', 'answer_start': 159}\n",
      "\n",
      "\n",
      "Text:  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "Question:  When were the Normans in Normandy?\n",
      "Answer:  {'text': '10th and 11th centuries', 'answer_start': 94}\n",
      "\n",
      "\n",
      "Text:  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "Question:  When were the Normans in Normandy?\n",
      "Answer:  {'text': 'in the 10th and 11th centuries', 'answer_start': 87}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"VAL DATA\")\n",
    "for idx in range(3, 6):\n",
    "    print(\"Text: \", val_texts[idx])\n",
    "    print(\"Question: \", val_questions[idx])\n",
    "    print(\"Answer: \", val_answers[idx])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZpYPQMbcOU9"
   },
   "source": [
    "# 3. Preprocess/Clean dataset as per BERT format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "nyqOFHyvt7Qg"
   },
   "outputs": [],
   "source": [
    "def process_dataset(answers, texts):\n",
    "    for answer, text in zip(answers, texts):\n",
    "        real_answer = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(real_answer)\n",
    "\n",
    "        # Exact match\n",
    "        if text[start_idx:end_idx] == real_answer:\n",
    "            answer['answer_end'] = end_idx\n",
    "        # answer is one character longer\n",
    "        elif text[start_idx - 1:end_idx - 1] == real_answer:\n",
    "            answer['answer_start'] = start_idx - 1\n",
    "            answer['answer_end'] = end_idx - 1\n",
    "        # answer is two characters longer\n",
    "        elif text[start_idx - 2:end_idx - 2] == real_answer:\n",
    "            answer['answer_start'] = start_idx - 2\n",
    "            answer['answer_end'] = end_idx - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "dQHz7Auvt7M8"
   },
   "outputs": [],
   "source": [
    "process_dataset(train_answers, train_texts)\n",
    "process_dataset(val_answers, val_texts)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(train_texts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, val_questions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "9CczcghbegGN"
   },
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start = []\n",
    "    end = []\n",
    "\n",
    "    for i, answer in enumerate(answers):\n",
    "        start_token = encodings.char_to_token(i, answer['answer_start'])\n",
    "        end_token = encodings.char_to_token(i, answer['answer_end'] - 1)\n",
    "\n",
    "        if start_token is None:\n",
    "            start_token = encodings.model_max_length\n",
    "        if end_token is None:\n",
    "            end_token = encodings.model_max_length\n",
    "\n",
    "        start.append(start_token)\n",
    "        end.append(end_token)\n",
    "\n",
    "    encodings.update({'start': start, 'end': end})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "J5agSUYpeiES"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoded_tensors = {}\n",
    "        for key, val in self.encodings.items():\n",
    "            tensor_at_idx = torch.tensor(val[idx])\n",
    "            encoded_tensors[key] = tensor_at_idx\n",
    "        return encoded_tensors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "fyEGFIy9ei8y"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_encodings)\n",
    "val_dataset = Dataset(val_encodings)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mB4IoJO6P-Mz"
   },
   "source": [
    "## 4. Train the BERT QnA model. Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBkFKxDftENv",
    "outputId": "03b6250a-7f76-4069-a9de-094206235320"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhGJcc2TtEID",
    "outputId": "6907f238-8fce-43ac-f98c-0d173d0881d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training loss 3.9835909605026245 and Validation Loss 3.306875057220459\n",
      "Epoch 1 Training loss 2.4406928277015685 and Validation Loss 1.9043096494674683\n",
      "Epoch 2 Training loss 1.25600115776062 and Validation Loss 1.6564743208885193\n",
      "Epoch 3 Training loss 0.7162760701775551 and Validation Loss 1.6332973337173462\n",
      "Epoch 4 Training loss 0.5061268813163042 and Validation Loss 1.6989549314975738\n",
      "Epoch 5 Training loss 0.3689735359326005 and Validation Loss 1.7415593361854553\n",
      "Epoch 6 Training loss 0.30243203073740005 and Validation Loss 1.5848237800598144\n",
      "Epoch 7 Training loss 0.20973721192218364 and Validation Loss 1.7167938137054444\n",
      "Epoch 8 Training loss 0.21440503989346327 and Validation Loss 2.1902471113204958\n",
      "Epoch 9 Training loss 0.15795133426785468 and Validation Loss 1.9124277901649476\n",
      "Epoch 10 Training loss 0.19473949896171688 and Validation Loss 2.0082615661621093\n",
      "Epoch 11 Training loss 0.15191162386909127 and Validation Loss 1.8077738332748412\n",
      "Epoch 12 Training loss 0.12570586572168396 and Validation Loss 2.0645176219940184\n",
      "Epoch 13 Training loss 0.17889058685861528 and Validation Loss 2.048735275268555\n",
      "Epoch 14 Training loss 0.15868613528087736 and Validation Loss 1.7832641506195068\n",
      "Epoch 15 Training loss 0.12029916445491835 and Validation Loss 1.9350903630256653\n",
      "Epoch 16 Training loss 0.14790292305406183 and Validation Loss 2.500196771621704\n",
      "Epoch 17 Training loss 0.12350249722949229 and Validation Loss 2.196108541190624\n",
      "Epoch 18 Training loss 0.12777529984014108 and Validation Loss 1.9633875870704651\n",
      "Epoch 19 Training loss 0.060943874046788554 and Validation Loss 2.433998117446899\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss, val_loss = 0, 0\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start = batch['start'].to(device)\n",
    "        end = batch['end'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start, end_positions=end)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, batch in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start = batch['start'].to(device)\n",
    "            end = batch['end'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start, end_positions=end)\n",
    "            loss = outputs[0]\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch} Training loss {train_loss} and Validation Loss {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXGv9wP7Qqzs"
   },
   "source": [
    "## 5. Perform an Inference and show the predicted vs ground truth answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "JiuP56kWxYn8"
   },
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    regex_articles = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "    s = re.sub(regex_articles, \" \", s)\n",
    "    s = \"\".join(ch for ch in s if ch not in string.punctuation)\n",
    "    s = \" \".join(s.split())\n",
    "    s = s.lower()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "JwbG6dhxtEFR"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = clean_text(prediction).split()\n",
    "    truth_tokens = clean_text(truth).split()\n",
    "    if not pred_tokens or not truth_tokens:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    if not common_tokens:\n",
    "        return 0\n",
    "\n",
    "    precision = len(common_tokens) / len(pred_tokens)\n",
    "    recall = len(common_tokens) / len(truth_tokens)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "OViZUrBetECU"
   },
   "outputs": [],
   "source": [
    "def predict(text, question, answer):\n",
    "    inputs = tokenizer.encode_plus(question, text, return_tensors='pt')\n",
    "    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    answer_start = torch.argmax(outputs[0])\n",
    "    answer_end = torch.argmax(outputs[1]) + 1\n",
    "    prediction = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "\n",
    "    exact_match = int(clean_text(prediction) == clean_text(answer))\n",
    "    f1_score = compute_f1(prediction, answer)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"True Answer: {answer}\")\n",
    "    print(f\"Exact Match: {exact_match}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjHYyfAmtD_g",
    "outputId": "3a938550-8500-4069-9b01-f33c6853eb2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the name of the girl?\n",
      "Prediction: cinderella\n",
      "True Answer: cindrella\n",
      "Exact Match: 0\n",
      "F1 Score: 0\n",
      "\n",
      "\n",
      "Question: Where did Cindrella live?\n",
      "Prediction: everest\n",
      "True Answer: everest\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0\n",
      "\n",
      "\n",
      "Question: How old was she?\n",
      "Prediction: 18 years old\n",
      "True Answer: 18\n",
      "Exact Match: 0\n",
      "F1 Score: 0.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"A girl named Cinderella was very pretty. She lived in a village named Everest. She was 18 years old. It was Cinderella who had to wake up each morning when it was still dark and cold to start the fire.  Cinderella who cooked the meals. Cinderella who kept the fire going\"\n",
    "\n",
    "questions = [\"What is the name of the girl?\",\n",
    "           \"Where did Cindrella live?\",\n",
    "           \"How old was she?\"\n",
    "\n",
    "          ]\n",
    "answers = [\"cindrella\",\n",
    "           \"everest\",\n",
    "           \"18\"\n",
    "          ]\n",
    "\n",
    "for q,a in zip(questions, answers):\n",
    "    predict(text, q, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuXyV-Ghymbz"
   },
   "source": [
    "Github Link: https://github.com/daminivichare66/Transformers_Bert_QnA"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
